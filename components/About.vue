<template>
    <div id="about" class="bg-white  scroll-mt-28">
        <div class="max-w-7xl mx-auto py-16 px-4 sm:px-6 lg:px-8">
            <div class="">
                <h2 class="text-3xl font-medium tracking-tight text-gray-900 sm:text-4xl">
                    About the project
                </h2>
                <p class="mt-8 text-base sm:text-xl text-gray-[#1A1A1A] max-w-prose">
                    We used a systematic review to identify 43 frameworks containing categories and subcategories of
                    risks from AI, which we extract into a living database of risks from AI and use a ‘best fit
                    framework synthesis’ approach to develop two taxonomies of risk to help navigate this database. 
                </p>
                <p class="mt-8 text-base sm:text-xl text-gray-[#1A1A1A] max-w-prose">
                    The high-level taxonomy, adapted from Yampolskiy 2016, classifies risks by its causal factors (1)
                    entity (human, AI), (2) intentionality (intentional, unintentional), and (3) timing (pre-deployment,
                    post-deployment). The mid-level taxonomy, adapted from Weidinger (2021) classifies risks into 7 AI
                    risk domains: (1) Discrimination & Toxicity, (2) Privacy & Security, (3) Misinformation, (4)
                    Malicious Actors & Misuse, (5) Human-Computer Interaction, (6) Socioeconomic & Environmental, and
                    (7) AI System Safety, Failures, & Limitations.  </p>
                <p class="mt-8 text-base sm:text-xl text-gray-[#1A1A1A] max-w-prose">
                    Our taxonomies make it possible to use our database to identify all mentions of a specific risk and
                    the sources from which these originate. They also provide a way to understand different versions of
                    such risks, for instance, to determine if they are presented as occurring pre-deployment or
                    post-deployment. With this database and these taxonomies, we aim to create a foundation for a more
                    coordinated, coherent, and complete approach to defining, auditing, and managing the risks posed by
                    AI systems.
                </p>
            </div>

        </div>
    </div>
</template>